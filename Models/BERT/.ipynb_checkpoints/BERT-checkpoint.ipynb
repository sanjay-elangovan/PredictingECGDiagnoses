{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56635b58",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee53322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ac2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ekg_denoised = pd.read_pickle('ekg_denoised.pkl')\n",
    "ekg_denoised = ekg_denoised.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f137938c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ICD9_CODE</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>4019</td>\n",
       "      <td>sinus rhythm. miniature r waves with r' patter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>4019</td>\n",
       "      <td>sinus rhythm with one premaeture atrial beat. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>4280</td>\n",
       "      <td>sinus rhythm. the p-r interval is prolonged. t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>42731</td>\n",
       "      <td>atrial fibrillation with rapid ventricular res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4019</td>\n",
       "      <td>sinus tachycardia with diffuse non-diagnostic ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ICD9_CODE                                               TEXT\n",
       "1602       4019  sinus rhythm. miniature r waves with r' patter...\n",
       "1551       4019  sinus rhythm with one premaeture atrial beat. ...\n",
       "3183       4280  sinus rhythm. the p-r interval is prolonged. t...\n",
       "5425      42731  atrial fibrillation with rapid ventricular res...\n",
       "62         4019  sinus tachycardia with diffuse non-diagnostic ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ekg_denoised.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a802382",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bdae1f",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e3dce3",
   "metadata": {},
   "source": [
    "### Loading Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73095608",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49350042",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acc636e",
   "metadata": {},
   "source": [
    "### Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c3ad1d",
   "metadata": {},
   "source": [
    "#### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35aa3e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = ekg_denoised['TEXT'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d35fbb6",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf4d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f7b4915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6536, 176)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180235d8",
   "metadata": {},
   "source": [
    "#### Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "769cbf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6536, 176)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3426a635",
   "metadata": {},
   "source": [
    "### Generating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce40a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70720735",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'last_hidden_states' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d7c19904bb54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_hidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'last_hidden_states' is not defined"
     ]
    }
   ],
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
